{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import keras\n",
    "board = keras.callbacks.TensorBoard(log_dir='./logs/artsnobs', histogram_freq=0, batch_size=100, write_graph=True)\n",
    "\n",
    "#Dynamically change learning rate based on 'val_acc' over time\n",
    "#change 0.8 to 0.75?\n",
    "#factor = 0.75\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.625, patience=7, min_lr=0.001, verbose=1)\n",
    "\n",
    "#Stop training when 'val_loss' stops improving after 15 epochs\n",
    "#patience was 15\n",
    "e_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "\n",
    "#Saves a checkpoint of the model every time its validation accuracy improves\n",
    "chkpt = keras.callbacks.ModelCheckpoint(\"artsnobs_chkpt.hdf5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "\n",
    "#Next 4 lines allows MASSIVE images to be loaded in and used\n",
    "import PIL\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "PIL.Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ethan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ethan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ethan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ethan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
    "# model.add(Conv2D(32, (3, 3), input_shape=(175, 175, 3)))\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(500, 500, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(BatchNormalization()) #added this\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3))) #changed 32 to 64\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3))) #added this\n",
    "model.add(Activation('relu')) #added this\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) #added this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ethan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ethan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# model.add(Dense(64)) #added this\n",
    "# model.add(Activation('sigmoid')) #added this\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3)) #3 for art_genre_set, 5 for dataset\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ethan\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ethan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adadelta', metrics = ['accuracy'])\n",
    "# model.summary()\n",
    "model.load_weights('artsnobs_chkpt.hdf5') #BE AWARE IF THIS IS ENABLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 #change this from 16, used 100 for dataset\n",
    "# train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, rotation_range=40, width_shift_range=0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, fill_mode = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19011 images belonging to 3 classes.\n",
      "Found 2112 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "train_generator = train_datagen.flow_from_directory('/Users/ethan/Documents/MLData/ArtSnobs/art_genre_set/train/', target_size = (500, 500), batch_size = batch_size, class_mode = 'categorical', color_mode='rgb')\n",
    "v_generator = test_datagen.flow_from_directory('/Users/ethan/Documents/MLData/ArtSnobs/art_genre_set/test/', target_size = (500, 500), batch_size = batch_size, class_mode = 'categorical', color_mode='rgb')\n",
    "\n",
    "# train_generator = train_datagen.flow_from_directory('/Users/ethan/Documents/MLData/ArtSnobs/dataset/dataset_updated/training_set/', target_size = (175, 175), batch_size = batch_size, class_mode = 'categorical', color_mode='rgb')\n",
    "# v_generator = test_datagen.flow_from_directory('/Users/ethan/Documents/MLData/ArtSnobs/dataset/dataset_updated/validation_set/', target_size = (175,175), batch_size = batch_size, class_mode = 'categorical', color_mode='rgb')\n",
    "# # train_generator = train_datagen.flow_from_directory('/Users/ethan/Documents/MLData/ArtSnobs/dataset/dataset_updated/training_set/', target_size = (150, 150), batch_size = batch_size, class_mode = 'categorical', color_mode='rgb')\n",
    "# # v_generator = test_datagen.flow_from_directory('/Users/ethan/Documents/MLData/ArtSnobs/dataset/dataset_updated/validation_set/', target_size = (150,150), batch_size = batch_size, class_mode = 'categorical', color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ethan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\ethan\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ethan\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 20/250\n",
      "1320/1320 [==============================] - 512s 388ms/step - loss: 0.8794 - acc: 0.5927 - val_loss: 0.9132 - val_acc: 0.5507\n",
      "\n",
      "Epoch 00020: val_acc improved from -inf to 0.55066, saving model to artsnobs_chkpt.hdf5\n",
      "Epoch 21/250\n",
      "1320/1320 [==============================] - 492s 373ms/step - loss: 0.8664 - acc: 0.5988 - val_loss: 0.9250 - val_acc: 0.5639\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.55066 to 0.56392, saving model to artsnobs_chkpt.hdf5\n",
      "Epoch 22/250\n",
      "1320/1320 [==============================] - 494s 374ms/step - loss: 0.8673 - acc: 0.6015 - val_loss: 0.9258 - val_acc: 0.5545\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.56392\n",
      "Epoch 23/250\n",
      "1320/1320 [==============================] - 516s 391ms/step - loss: 0.8696 - acc: 0.5991 - val_loss: 0.9264 - val_acc: 0.5724\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.56392 to 0.57244, saving model to artsnobs_chkpt.hdf5\n",
      "Epoch 24/250\n",
      "1320/1320 [==============================] - 495s 375ms/step - loss: 0.8607 - acc: 0.5983 - val_loss: 0.9435 - val_acc: 0.5492\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.57244\n",
      "Epoch 25/250\n",
      "1320/1320 [==============================] - 484s 367ms/step - loss: 0.8631 - acc: 0.6028 - val_loss: 1.0875 - val_acc: 0.5417\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.57244\n",
      "Epoch 26/250\n",
      "1320/1320 [==============================] - 499s 378ms/step - loss: 0.8701 - acc: 0.5985 - val_loss: 0.9176 - val_acc: 0.5705\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.57244\n",
      "Epoch 27/250\n",
      "1320/1320 [==============================] - 517s 392ms/step - loss: 0.8625 - acc: 0.6013 - val_loss: 0.9435 - val_acc: 0.5644\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.57244\n",
      "Epoch 28/250\n",
      "1320/1320 [==============================] - 513s 389ms/step - loss: 0.8636 - acc: 0.6005 - val_loss: 0.9291 - val_acc: 0.5445\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.57244\n",
      "Epoch 29/250\n",
      "1320/1320 [==============================] - 519s 393ms/step - loss: 0.8582 - acc: 0.6045 - val_loss: 0.8915 - val_acc: 0.5611\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.57244\n",
      "Epoch 30/250\n",
      "1320/1320 [==============================] - 500s 379ms/step - loss: 0.8524 - acc: 0.6079 - val_loss: 0.8987 - val_acc: 0.5687\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.625.\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.57244\n",
      "Epoch 31/250\n",
      "1320/1320 [==============================] - 501s 379ms/step - loss: 0.8287 - acc: 0.6202 - val_loss: 0.8919 - val_acc: 0.5786\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.57244 to 0.57860, saving model to artsnobs_chkpt.hdf5\n",
      "Epoch 32/250\n",
      "1320/1320 [==============================] - 498s 377ms/step - loss: 0.8239 - acc: 0.6237 - val_loss: 0.9238 - val_acc: 0.5819\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.57860 to 0.58191, saving model to artsnobs_chkpt.hdf5\n",
      "Epoch 33/250\n",
      "1320/1320 [==============================] - 502s 380ms/step - loss: 0.8254 - acc: 0.6281 - val_loss: 0.9232 - val_acc: 0.5772\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.58191\n",
      "Epoch 34/250\n",
      "1320/1320 [==============================] - 492s 373ms/step - loss: 0.8260 - acc: 0.6288 - val_loss: 0.9602 - val_acc: 0.5653\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.58191\n",
      "Epoch 35/250\n",
      "1320/1320 [==============================] - 493s 373ms/step - loss: 0.8247 - acc: 0.6296 - val_loss: 0.9806 - val_acc: 0.5587\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.58191\n",
      "Epoch 36/250\n",
      "1320/1320 [==============================] - 487s 369ms/step - loss: 0.8213 - acc: 0.6277 - val_loss: 0.9311 - val_acc: 0.5511\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.58191\n",
      "Epoch 37/250\n",
      "1320/1320 [==============================] - 485s 368ms/step - loss: 0.8234 - acc: 0.6311 - val_loss: 0.9124 - val_acc: 0.5516\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.58191\n",
      "Epoch 38/250\n",
      "1320/1320 [==============================] - 486s 368ms/step - loss: 0.8236 - acc: 0.6341 - val_loss: 0.8943 - val_acc: 0.5791\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.58191\n",
      "Epoch 39/250\n",
      "1320/1320 [==============================] - 523s 397ms/step - loss: 0.8266 - acc: 0.6290 - val_loss: 0.9014 - val_acc: 0.5753\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.390625.\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.58191\n",
      "Epoch 40/250\n",
      "1320/1320 [==============================] - 497s 376ms/step - loss: 0.8025 - acc: 0.6393 - val_loss: 0.9417 - val_acc: 0.5890\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.58191 to 0.58902, saving model to artsnobs_chkpt.hdf5\n",
      "Epoch 41/250\n",
      "1320/1320 [==============================] - 496s 375ms/step - loss: 0.7985 - acc: 0.6476 - val_loss: 0.9335 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.58902 to 0.58996, saving model to artsnobs_chkpt.hdf5\n",
      "Epoch 42/250\n",
      "1320/1320 [==============================] - 505s 382ms/step - loss: 0.7990 - acc: 0.6439 - val_loss: 0.9027 - val_acc: 0.6009\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.58996 to 0.60085, saving model to artsnobs_chkpt.hdf5\n",
      "Epoch 43/250\n",
      "1320/1320 [==============================] - 505s 383ms/step - loss: 0.8079 - acc: 0.6397 - val_loss: 0.9618 - val_acc: 0.5795\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.60085\n",
      "Epoch 44/250\n",
      "1320/1320 [==============================] - 512s 388ms/step - loss: 0.7956 - acc: 0.6442 - val_loss: 0.8806 - val_acc: 0.5866\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.60085\n",
      "Epoch 45/250\n",
      "1320/1320 [==============================] - 495s 375ms/step - loss: 0.8026 - acc: 0.6389 - val_loss: 0.9506 - val_acc: 0.5829\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.60085\n",
      "Epoch 46/250\n",
      "1320/1320 [==============================] - 508s 385ms/step - loss: 0.7973 - acc: 0.6456 - val_loss: 0.9319 - val_acc: 0.5753\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.60085\n",
      "Epoch 47/250\n",
      "1320/1320 [==============================] - 506s 383ms/step - loss: 0.8027 - acc: 0.6438 - val_loss: 0.9813 - val_acc: 0.5838\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.60085\n",
      "Epoch 48/250\n",
      "1320/1320 [==============================] - 496s 376ms/step - loss: 0.8000 - acc: 0.6412 - val_loss: 0.9344 - val_acc: 0.5909\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.60085\n",
      "Epoch 49/250\n",
      "1320/1320 [==============================] - 497s 376ms/step - loss: 0.8016 - acc: 0.6440 - val_loss: 0.9473 - val_acc: 0.5720\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.244140625.\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.60085\n",
      "Epoch 50/250\n",
      "1320/1320 [==============================] - 476s 361ms/step - loss: 0.7827 - acc: 0.6497 - val_loss: 0.9016 - val_acc: 0.5881\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.60085\n",
      "Epoch 51/250\n",
      "1320/1320 [==============================] - 498s 377ms/step - loss: 0.7772 - acc: 0.6535 - val_loss: 0.8899 - val_acc: 0.5857\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.60085\n",
      "Epoch 52/250\n",
      "1320/1320 [==============================] - 485s 367ms/step - loss: 0.7937 - acc: 0.6494 - val_loss: 0.8833 - val_acc: 0.5956\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.60085\n",
      "Epoch 53/250\n",
      "1320/1320 [==============================] - 490s 371ms/step - loss: 0.7831 - acc: 0.6533 - val_loss: 0.9492 - val_acc: 0.5814\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.60085\n",
      "Epoch 54/250\n",
      "1320/1320 [==============================] - 485s 367ms/step - loss: 0.7771 - acc: 0.6547 - val_loss: 0.9489 - val_acc: 0.5938\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.60085\n",
      "Epoch 55/250\n",
      "1320/1320 [==============================] - 486s 368ms/step - loss: 0.7843 - acc: 0.6503 - val_loss: 0.9041 - val_acc: 0.5909\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.60085\n",
      "Epoch 56/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1320/1320 [==============================] - 501s 379ms/step - loss: 0.7833 - acc: 0.6481 - val_loss: 0.8970 - val_acc: 0.5777\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.152587890625.\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.60085\n",
      "Epoch 57/250\n",
      "1320/1320 [==============================] - 523s 396ms/step - loss: 0.7655 - acc: 0.6609 - val_loss: 0.9173 - val_acc: 0.5966\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.60085\n",
      "Epoch 58/250\n",
      "1320/1320 [==============================] - 492s 373ms/step - loss: 0.7769 - acc: 0.6558 - val_loss: 0.9051 - val_acc: 0.5966\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.60085\n",
      "Epoch 59/250\n",
      "1320/1320 [==============================] - 494s 375ms/step - loss: 0.7679 - acc: 0.6583 - val_loss: 0.8950 - val_acc: 0.5843\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.60085\n",
      "Epoch 60/250\n",
      "1320/1320 [==============================] - 485s 368ms/step - loss: 0.7700 - acc: 0.6548 - val_loss: 0.9401 - val_acc: 0.5848\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.60085\n",
      "Epoch 61/250\n",
      "1320/1320 [==============================] - 509s 385ms/step - loss: 0.7693 - acc: 0.6570 - val_loss: 0.8949 - val_acc: 0.5909\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.60085\n",
      "Epoch 62/250\n",
      "1320/1320 [==============================] - 492s 373ms/step - loss: 0.7685 - acc: 0.6596 - val_loss: 0.9461 - val_acc: 0.5942\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.60085\n",
      "Epoch 63/250\n",
      "1320/1320 [==============================] - 486s 368ms/step - loss: 0.7738 - acc: 0.6575 - val_loss: 0.9504 - val_acc: 0.5994\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.095367431640625.\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.60085\n",
      "Epoch 64/250\n",
      "1319/1320 [============================>.] - ETA: 0s - loss: 0.7688 - acc: 0.6583"
     ]
    }
   ],
   "source": [
    "#change steps_per_epoch = 2500 to entire size of dataset (21123)\n",
    "#change validation_steps = 1250 to half the entire size of the dataset (10561)\n",
    "\n",
    "model.fit_generator(train_generator, steps_per_epoch = 21123 // batch_size, epochs = 250, validation_data =v_generator, validation_steps = 10561 // batch_size, callbacks = [board, e_stop, reduce_lr, chkpt], workers = 6, initial_epoch = 19)\n",
    "model.save_weights('artsnobs_weights_correct_steps_per_epoch_valid_steps.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://jovianlin.io/saving-loading-keras-models/\n",
    "#use the link above to load the full model back into the notebook to continue training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
